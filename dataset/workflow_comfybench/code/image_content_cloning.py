# create nodes by instantiation
checkpointloadersimple_1 = CheckpointLoaderSimple(ckpt_name="""dreamshaper_8.safetensors""")
vaeloader_2 = VAELoader(vae_name="""vae-ft-mse-840000-ema-pruned.safetensors""")
ipadaptermodelloader_3 = IPAdapterModelLoader(ipadapter_file="""ip-adapter_sd15.safetensors""")
clipvisionloader_4 = CLIPVisionLoader(clip_name="""CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors""")
loadimage_6 = LoadImage(image="""woman_portrait.jpg""")
cliptextencode_7 = CLIPTextEncode(text="""beautiful renaissance girl, detailed""")
cliptextencode_8 = CLIPTextEncode(text="""blurry, horror""")
ksampler_9 = KSampler(seed=937143485600286, control_after_generate="""randomize""", steps=25, cfg=6, sampler_name="""ddim""", scheduler="""ddim_uniform""", denoise=1)
emptylatentimage_10 = EmptyLatentImage(width=512, height=512, batch_size=1)
vaedecode_11 = VAEDecode()
saveimage_12 = SaveImage(filename_prefix="""IPAdapter""")
ipadapteradvanced_16 = IPAdapterAdvanced(weight=1, weight_type="""linear""", combine_embeds="""concat""", start_at=0, end_at=1, embeds_scaling="""V only""")

# link nodes by invocation
model_1, clip_1, vae_1 = checkpointloadersimple_1()
ipadapter_3 = ipadaptermodelloader_3()
image_6, mask_6 = loadimage_6()
conditioning_8 = cliptextencode_8(clip=clip_1)
latent_10 = emptylatentimage_10()
vae_2 = vaeloader_2()
conditioning_7 = cliptextencode_7(clip=clip_1)
clip_vision_4 = clipvisionloader_4()
model_16 = ipadapteradvanced_16(model=model_1, ipadapter=ipadapter_3, image=image_6, image_negative=None, attn_mask=None, clip_vision=clip_vision_4)
latent_9 = ksampler_9(model=model_16, positive=conditioning_7, negative=conditioning_8, latent_image=latent_10)
image_11 = vaedecode_11(samples=latent_9, vae=vae_2)
result_12 = saveimage_12(images=image_11)
