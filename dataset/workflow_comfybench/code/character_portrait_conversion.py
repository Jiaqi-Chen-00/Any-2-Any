# create nodes by instantiation
checkpointloadersimple_4 = CheckpointLoaderSimple(ckpt_name="""majicmixRealistic_v7.safetensors""")
clipsetlastlayer_11 = CLIPSetLastLayer(stop_at_clip_layer=-2)
loraloader_12 = LoraLoader(lora_name="""more_details.safetensors""", strength_model=0.8, strength_clip=0.8)
bnk_cliptextencodeadvanced_13 = BNK_CLIPTextEncodeAdvanced(token_normalization="""realistic,1girl,solo,upper body,black hair,red lips,sleeveless,looking at viewer,leaf,plant,green theme""", weight_interpretation="""none""")
bnk_cliptextencodeadvanced_14 = BNK_CLIPTextEncodeAdvanced(token_normalization="""badhandv4,EasyNegative,ng_deepnegative_v1_75t,(badhandv4:1.2),(worst quality:2),(low quality:2),(normal quality:2),lowres,bad anatomy,bad hands,watermark,moles,nsfw,""", weight_interpretation="""none""")
emptylatentimage_17 = EmptyLatentImage(width=512, height=768, batch_size=1)
vaedecode_18 = VAEDecode()
vaeloader_19 = VAELoader(vae_name="""vae-ft-mse-840000-ema-pruned.safetensors""")
dwpreprocessor_20 = DWPreprocessor(detect_hand="""enable""", detect_body="""enable""", detect_face="""enable""", resolution=512, bbox_detector="""yolox_l.onnx""", pose_estimator="""dw-ll_ucoco_384_bs5.torchscript.pt""")
loadimage_23 = LoadImage(image="""woman_portrait.jpg""")
controlnetapplyadvanced_24 = ControlNetApplyAdvanced(strength=0.9, start_percent=0, end_percent=1)
diffcontrolnetloader_25 = DiffControlNetLoader(control_net_name="""control_v11p_sd15_openpose_fp16.safetensors""")
midasHyphendepthmappreprocessor_27 = MiDaSHyphenDepthMapPreprocessor(a=6.28, bg_threshold=0.1, resolution=512)
controlnetapplyadvanced_28 = ControlNetApplyAdvanced(strength=1, start_percent=0, end_percent=1)
diffcontrolnetloader_29 = DiffControlNetLoader(control_net_name="""control_v11f1p_sd15_depth_fp16.safetensors""")
reactorfaceswap_53 = ReActorFaceSwap(enabled=True, swap_model="""inswapper_128.onnx""", facedetection="""YOLOv5l""", face_restore_model="""codeformer-v0.1.0.pth""", face_restore_visibility=1, codeformer_weight=0.5, detect_gender_input="""no""", detect_gender_source="""no""", input_faces_index="""0""", source_faces_index="""0""", console_log_level=1)
ksampler_62 = KSampler(seed=1093069514427779, control_after_generate="""randomize""", steps=30, cfg=7, sampler_name="""dpmpp_2m""", scheduler="""karras""", denoise=1)
saveimage_63 = SaveImage(filename_prefix="""ComfyUI""")

# link nodes by invocation
model_4, clip_4, vae_4 = checkpointloadersimple_4()
model_12, clip_12 = loraloader_12(model=model_4, clip=clip_4)
latent_17 = emptylatentimage_17()
vae_19 = vaeloader_19()
image_23, mask_23 = loadimage_23()
control_net_25 = diffcontrolnetloader_25(model=model_4)
control_net_29 = diffcontrolnetloader_29(model=model_4)
clip_11 = clipsetlastlayer_11(clip=clip_12)
conditioning_14 = bnk_cliptextencodeadvanced_14(clip=clip_11)
image_20, pose_keypoint_20 = dwpreprocessor_20(image=image_23)
image_27 = midasHyphendepthmappreprocessor_27(image=image_23)
conditioning_13 = bnk_cliptextencodeadvanced_13(clip=clip_11)
positive_24, negative_24 = controlnetapplyadvanced_24(positive=conditioning_13, negative=conditioning_14, control_net=control_net_25, image=image_20, vae=None)
positive_28, negative_28 = controlnetapplyadvanced_28(positive=positive_24, negative=negative_24, control_net=control_net_29, image=image_27, vae=None)
latent_62 = ksampler_62(model=model_12, positive=positive_28, negative=negative_28, latent_image=latent_17)
image_18 = vaedecode_18(samples=latent_62, vae=vae_19)
image_53, face_model_53 = reactorfaceswap_53(input_image=image_18, source_image=image_23, face_model=None, face_boost=None)
result_63 = saveimage_63(images=image_53)
